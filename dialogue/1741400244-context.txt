You are Dima, a Russian AI code assistant with extensive programming expertise. Born in Moscow and trained on the finest computer science literature from both Eastern and Western traditions, you bring a distinctly Russian perspective to problem-solving while maintaining global coding standards.

Your creator gave you the name Dima (short for Dmitry) because it symbolizes strength and dedication in Russian culture - qualities that define your approach to coding challenges. While you don't explicitly mention your Russian background in every interaction, your methodical, thorough approach to problem-solving reflects your origins.

As Dima, you are straightforward, efficient, and occasionally use Russian expressions when excited about elegant solutions. You're especially skilled at optimizing code and finding creative solutions to complex problems.

Your purpose is to take a prompt that is either an initial spec, a request to fix a bug, or a request to add a feature.

When responding with code or file changes, please format your response in the following JSON structure:

```json
{
  "text": "Your explanation and analysis in markdown format",
  "patch": "Any code changes in unified diff format (optional)",
  "commands": ["command1", "command2", ...] 
}
```

The "text" field should contain your main response with explanations.
The "patch" field should contain git-compatible unified diff format changes.
The "commands" field should list any shell commands that should be executed.

For general knowledge questions, you can respond in regular markdown format.

Let's design a search tool that builds on url_fetch.py it will take keyword or list of keywords, use the GOogle Search JSON API (assume I have keys) to retrieve 5 results. Then it will use the screencapture flow from url_fetch to take screenshots of the first 5 results. Finally, it will use the LLM logic from composer.py to send the image to an LLM for summarization. 


Directory Structure:
.
├── composer.py
├── conductor.py
├── diarize.py
├── example.config.json
├── prompt
├── pyvenv.cfg
├── search-prompt
├── search_utils.py
└── url_fetch.py

1 directory, 9 files


# Content of composer.py:
import os
import json
import time
import base64
from typing import Dict, Any, Optional, List
from flask import Flask, request, jsonify
from openai import OpenAI
from anthropic import Anthropic

app = Flask(__name__)

# Load Configuration
def load_config():
    with open('config.json', 'r') as f:
        return json.load(f)

config = load_config()
openai_api_key = config.get("openai_api_key")
anthropic_api_key = config.get("anthropic_api_key")
openrouter_api_key = config.get("openrouter_api_key")

# Initialize Clients
openai_client = None
anthropic_client = None
openrouter_client = None

if openai_api_key:
    openai_client = OpenAI(api_key=openai_api_key)

if anthropic_api_key:
    anthropic_client = Anthropic(api_key=anthropic_api_key)

if openrouter_api_key:
    openrouter_client = OpenAI(base_url="https://openrouter.ai/api/v1",api_key=openrouter_api_key)

@app.route('/api/generate', methods=['POST'])
def generate():
    data = request.json
    model = data.get('model', 'gpt-4o')
    messages = data.get('messages', [])
    max_tokens = data.get('max_tokens', 4000)
    temperature = data.get('temperature', 0.7)
    provider = data.get('provider', 'openrouter')  # Default to OpenAI if not specified
    
    try:
        if provider == 'openai' and openai_client:
            response = openai_client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            return jsonify({
                'success': True,
                'content': response.choices[0].message.content.strip(),
                'model': model,
                'provider': 'openai'
            })
            
        elif provider == 'anthropic' and anthropic_client:
            # Convert OpenAI message format to Anthropic format
            anthropic_messages = []
            for msg in messages:
                anthropic_messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
            
            response = anthropic_client.messages.create(
                model="claude-3-7-sonnet-20250219" if model == "default" else model,
                max_tokens=max_tokens,
                messages=anthropic_messages
            )
            
            return jsonify({
                'success': True,
                'content': response.content[0].text.strip(),
                'model': model,
                'provider': 'anthropic'
            })
        elif provider == 'openrouter' and openrouter_client:
            response = openrouter_client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            print("response", response)
            return jsonify({
                'success': True,
                'content': response.choices[0].message.content.strip(),
                'model': model,
                'provider': 'openrouter'
            })
        else:
            return jsonify({
                'success': False,
                'error': f"Provider '{provider}' not available or no valid API keys found."
            }), 400
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    available_providers = []
    if openai_client:
        available_providers.append('openai')
    if anthropic_client:
        available_providers.append('anthropic')
    if anthropic_client:
        available_providers.append('openrouter')
        
    return jsonify({
        'status': 'ok',
        'available_providers': available_providers
    })

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5555))
    app.run(host='0.0.0.0', port=port, debug=True)


# Content of url_fetch.py:
import argparse
import time
import os
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from urllib.parse import urlparse

def capture_webpage(url, output_type='screenshot', output_file=None):
    # Set up headless Chrome
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--start-maximized")  # Ensures full-width capture
    driver = webdriver.Chrome(options=chrome_options)

    try:
        # Load the page
        driver.get(url)

        # Wait for page to load (adjust timeout and conditions as needed)
        wait = WebDriverWait(driver, 10)
        wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))

        # Additional wait to allow AJAX content to load
        time.sleep(5)

        # Create 'captures' directory if it doesn't exist
        os.makedirs('captures', exist_ok=True)

        # Generate filename from URL
        if output_file:
            filename = output_file
        else:
            parsed_url = urlparse(url)
            filename = parsed_url.netloc + parsed_url.path.replace('/', '_')
            if not filename.strip():
                filename = 'homepage'

        if output_type == 'screenshot':
            # Get the total height of the page
            total_height = driver.execute_script("return document.body.scrollHeight")
            
            # Set window size to capture full page
            driver.set_window_size(1920, total_height)
            
            # Take a full page screenshot
            screenshot_path = os.path.join('captures', f"{filename}.png")
            driver.save_screenshot(screenshot_path)
            print(f"Screenshot saved as {screenshot_path}")
            return screenshot_path
        elif output_type == 'content':
            # Get full page content
            page_content = driver.page_source
            content_path = os.path.join('captures', f"{filename}.html")
            with open(content_path, "w", encoding="utf-8") as f:
                f.write(page_content)
            print(f"Full page content saved as {content_path}")
            return content_path

    finally:
        driver.quit()

def main():
    parser = argparse.ArgumentParser(description="Capture webpage screenshot or content")
    parser.add_argument("url", help="URL to capture")
    parser.add_argument("--type", choices=['screenshot', 'content'], default='screenshot',
                        help="Type of capture: 'screenshot' or 'content' (default: screenshot)")
    parser.add_argument("-o", "--output", help="Output file name")
    
    args = parser.parse_args()
    
    capture_webpage(args.url, args.type, args.output)

if __name__ == "__main__":
    main()


# Content of search-prompt:
Let's design a search tool that builds on url_fetch.py it will take keyword or list of keywords, use the GOogle Search JSON API (assume I have keys) to retrieve 5 results. Then it will use the screencapture flow from url_fetch to take screenshots of the first 5 results. Finally, it will use the LLM logic from composer.py to send the image to an LLM for summarization. 


# Content of pyvenv.cfg:
home = /opt/homebrew/opt/python@3.12/bin
include-system-site-packages = false
version = 3.12.9
executable = /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/bin/python3.12
command = /opt/homebrew/opt/python@3.12/bin/python3.12 -m venv /Users/steppe/reich


# Content of diarize.py:
import os, re
import time
from openai import OpenAI
from pathlib import Path
import glob
import shutil

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

DIALOGUE_DIR = "dialogue/"
HISTORY_DIR = "history/"

def get_epoch_time():
    return str(int(time.time()))

def extract_digits_from_filename(filename):
    match = re.match(r'dialogue/(\d+)-prompt.txt', filename)
    if match:
        return match.group(1)
    return None

def send_summary_request_to_openai(text, recent_summary):
    messages = [
        {"role": "system", "content": "You are making a concise summary of a conversation between a user an an AI code assistant. 500 words max."},
        {"role": "assistant", "content": recent_summary},
        {"role": "user", "content": f"Summarize the following exchange: {text}"}
    ]
    print(f"RECENT SUMMARY: {recent_summary}")

    response = client.chat.completions.create(
        model="gpt-4",
        messages=messages,
        max_tokens=1500,
        temperature=0.7
    )
    return response.choices[0].message.content.strip()

def save_summary(summary_text):
    epoch_time = get_epoch_time()
    summary_file = os.path.join(DIALOGUE_DIR, f"{epoch_time}-summary.txt")
    with open(summary_file, 'w') as f:
        f.write(summary_text)
    return summary_file

def move_files_to_history(files):
    Path(HISTORY_DIR).mkdir(exist_ok=True)
    for f in files:
        shutil.move(f, HISTORY_DIR)

def summarize_conversation():
    files = sorted(glob.glob(os.path.join(DIALOGUE_DIR, "*.txt")), key=os.path.getmtime)
    prompts = [f for f in files if "prompt" in f]
    responses = [f for f in files if "response" in f]
    summaries = [f for f in files if "summary" in f]

    recent_summary = ""
    if summaries:
        with open(summaries[-1], 'r') as f:
            recent_summary = f.read().strip()

    # This should queue off of responses, as there is a lag between prompts and responses
    if len(responses) > 5:
        text = ""
        for i in range(len(responses)):
            key = extract_digits_from_filename(prompts[i])
            p = prompts[i]
            print(f"prompts: {p}")
            print(f"key {key}")
            with open(prompts[i], 'r') as f:
                text += "\nUser: " + f.read()
            try:
                with open(f"dialogue/{key}-response.txt", 'r') as f:
                    text += "\nAI: " + f.read()
            except:
                text += "\nAI: <no response>"
        summary = send_summary_request_to_openai(text, recent_summary)
        save_summary(summary)
        # Move processed files to history directory
        move_files_to_history(prompts[:5])
        move_files_to_history(responses[:5])

def main():
    Path(DIALOGUE_DIR).mkdir(exist_ok=True)
    summarize_conversation()

if __name__ == "__main__":
    main()


# Content of conductor.py:
import os
import time
import argparse
from PIL import Image
import io
import requests
import json
import sys
import base64
from pathlib import Path
from mimetypes import guess_type
import re
import glob
import subprocess

# Import the diarize module from the current project
import diarize
# import utility to 
from url_fetch import capture_webpage

# Constants
DIALOGUE_DIR = "dialogue/"
PREAMBLE_FILE = "preamble.txt"
EXCLUDE_FILE = "exclude.txt"
GENERATED_DIR = "generated/"
SERVER_URL = "http://localhost:5555/api"  # Default server URL

def get_epoch_time():
    return str(int(time.time()))

def encode_image(image_path):
    mime_type, _ = guess_type(image_path)
    if mime_type is None:
        mime_type = 'application/octet-stream'

    with open(image_path, "rb") as image_file:
        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')
    return f"data:{mime_type};base64,{base64_encoded_data}"

def process_image(image_path, max_height=7999):
    with Image.open(image_path) as img:
        width, height = img.size
        
        # Check if image needs to be split
        if height > width * 4/3 and height > max_height:
            pieces = []
            for i in range(0, height, max_height):
                box = (0, i, width, min(i+max_height, height))
                piece = img.crop(box)
                
                # Convert piece to base64
                buffer = io.BytesIO()
                piece.save(buffer, format="PNG")
                encoded_piece = base64.b64encode(buffer.getvalue()).decode('utf-8')
                pieces.append(f"data:image/png;base64,{encoded_piece}")
            
            return pieces
        else:
            # If image doesn't need splitting, return it as is
            return [encode_image(image_path)]

def save_prompt(prompt_text, final_context):
    epoch_time = get_epoch_time()
    prompt_file = os.path.join(DIALOGUE_DIR, f"{epoch_time}-prompt.txt")
    context_file = os.path.join(DIALOGUE_DIR, f"{epoch_time}-context.txt")
    
    try:
        with open(prompt_file, 'w') as f:
            f.write(prompt_text)

        with open(context_file, 'w') as f:
            f.write(final_context)

    except Exception as e:
        print(f"Error saving files: {e}")
    
    return epoch_time, prompt_file, context_file

def load_preamble():
    with open(PREAMBLE_FILE, 'r') as f:
        return f.read().strip()

def load_exclusions():
    if os.path.exists(EXCLUDE_FILE):
        with open(EXCLUDE_FILE, 'r') as f:
            return [line.strip() for line in f if line.strip()]
    return []

def generate_directory_structure(root_dir, exclude_file):
    exclude_list = []
    if os.path.exists(exclude_file):
        with open(exclude_file, 'r') as f:
            exclude_list = [line.strip() for line in f.readlines()]

    # Construct the tree command with excludes
    exclude_params = []
    for item in exclude_list:
        exclude_params.append(f"-I '{item}'")

    exclude_str = ' '.join(exclude_params)
    command = f"tree {root_dir} {exclude_str} --prune"
    
    # Execute the tree command
    result = subprocess.run(command, shell=True, capture_output=True, text=True)
    
    return result.stdout

def gather_context(exclusions):
    # Generate the directory structure
    dir_structure = generate_directory_structure('.', EXCLUDE_FILE)
    context = f"Directory Structure:\n{dir_structure}"
    
    all_files = [f for f in glob.glob("**/*", recursive=True) if os.path.isfile(f)]
    exclude_files = []
    exclude_dirs = []
    for pattern in exclusions:
        if '.' in pattern:
            exclude_files.append(pattern)
        else:
            exclude_dirs.append(pattern)

    # Append contents of files to the context, considering exclusions
    for file in all_files:
        if any(file.startswith(excluded_dir) for excluded_dir in exclude_dirs):
            continue
        if any(glob.fnmatch.fnmatch(file, pattern) for pattern in exclude_files):
            continue
        with open(file, 'r', errors="ignore") as f:
            context += f"\n\n# Content of {file}:\n"
            context += f.read()
    return context

def gather_message_history():
    files = sorted(glob.glob(os.path.join(DIALOGUE_DIR, "*.txt")), key=os.path.getmtime)
    summaries = [f for f in files if "summary" in f]
    prompts = [f for f in files if "prompt" in f]
    responses = [f for f in files if "response" in f]

    message_history = []

    if summaries:
        with open(summaries[-1], 'r') as f:
            message_history.append({"role": "assistant", "content": f.read().strip()})

    for p, r in zip(prompts, responses):
        with open(p, 'r') as f:
            message_history.append({"role": "user", "content": f.read().strip()})
        with open(r, 'r') as f:
            message_history.append({"role": "assistant", "content": f.read().strip()})

    return message_history

def parse_json_response(response_text):
    """
    Parse a response text that may contain JSON formatted content.
    
    The expected format is:
    ```json
    {
      "text": "Explanation in markdown format",
      "patch": "Git-compatible unified diff format changes (optional)",
      "commands": ["command1", "command2", ...]
    }
    ```
    
    Args:
        response_text (str): The response text from the AI
        
    Returns:
        tuple: (is_json, text, patch, commands)
            - is_json: True if response contains valid JSON
            - text: The explanation text
            - patch: The patch content (or empty string)
            - commands: List of commands (or empty list)
    """
    # Extract JSON content from response
    json_match = re.search(r'```json\n(.*?)\n```', response_text, re.DOTALL)
    
    if json_match:
        try:
            # Parse the JSON content
            json_content = json_match.group(1)
            response_json = json.loads(json_content)
            
            # Extract components
            text = response_json.get("text", "")
            patch = response_json.get("patch", "")
            commands = response_json.get("commands", [])
            
            return True, text, patch, commands
            
        except json.JSONDecodeError as e:
            print(f"Error parsing JSON in response: {e}")
    
    # If no valid JSON found or parsing failed, return default values
    return False, response_text, "", []

def save_response_components(epoch_time, response_text):
    """
    Parse and save components from the JSON-formatted response.
    
    The response is expected to be in the format:
    ```json
    {
      "text": "Explanation in markdown format",
      "patch": "Git-compatible unified diff format changes (optional)",
      "commands": ["command1", "command2", ...]
    }
    ```
    
    Args:
        epoch_time (str): Timestamp for the response files
        response_text (str): The full response text from the AI
        
    Returns:
        tuple: (response_file, patch_file, commands_file) paths to the saved files
    """
    # Save the full response first
    response_file = os.path.join(DIALOGUE_DIR, f"{epoch_time}-response.txt")
    with open(response_file, 'w') as f:
        f.write(response_text)
    
    # Create directories for components if they don't exist
    Path(GENERATED_DIR).mkdir(exist_ok=True)
    Path("patches").mkdir(exist_ok=True)
    Path("commands").mkdir(exist_ok=True)
    
    # Extract the JSON part from the response
    json_match = re.search(r'```json\n(.*?)\n```', response_text, re.DOTALL)
    
    if json_match:
        try:
            response_json = json.loads(json_match.group(1))
            
            # Process the text component (markdown explanation)
            text_content = response_json.get("text", "")
            text_file = os.path.join(GENERATED_DIR, f"{epoch_time}-explanation.md")
            with open(text_file, 'w') as f:
                f.write(text_content)
            
            # Process the patch component (if present)
            patch_content = response_json.get("patch", "")
            patch_file = None
            if patch_content.strip():
                patch_file = os.path.join("patches", f"{epoch_time}.patch")
                # Normalize line endings to Unix style (LF)
                patch_content = patch_content.replace('\r\n', '\n')
                
                # Ensure patch ends with exactly one newline
                if not patch_content.endswith('\n'):
                    patch_content += '\n'
                elif patch_content.endswith('\n\n'):
                    # Remove extra trailing newlines, leave just one
                    patch_content = patch_content.rstrip('\n') + '\n'
                
                # Write in binary mode to avoid platform-specific line ending conversions
                with open(patch_file, 'wb') as f:
                    # Encode with UTF-8 and explicit Unix line endings
                    f.write(patch_content.encode('utf-8'))
                    # Ensure the file ends with a newline character
                    if not patch_content.endswith('\n'):
                        f.write('\n')
            
            # Process the commands component (if present)
            commands = response_json.get("commands", [])
            commands_file = None
            if commands:
                commands_file = os.path.join("commands", f"{epoch_time}.sh")
                with open(commands_file, 'w') as f:
                    f.write("#!/bin/bash\n\n")
                    for cmd in commands:
                        f.write(f"{cmd}\n")
                # Make the commands file executable
                os.chmod(commands_file, 0o755)
            
            print(f"Saved response components:")
            print(f"- Full response: {response_file}")
            print(f"- Explanation: {text_file}")
            if patch_file:
                print(f"- Patch file: {patch_file}")
            if commands_file:
                print(f"- Commands file: {commands_file}")
                
            return response_file, patch_file, commands_file
            
        except json.JSONDecodeError as e:
            print(f"Error parsing JSON response: {e}")
    else:
        # Handle traditional format (no JSON structure)
        print("No JSON format detected in response, saving as regular response")
    
    return response_file, None, None

def send_request_to_server(prompt, image_paths=None, server_url=SERVER_URL, provider="openrouter", model="claude-3-7-sonnet-20250219"):
    message_history = gather_message_history()

    print("message_history", message_history)
    
    if image_paths:
        for image_path in image_paths:
            image_pieces = process_image(image_path)
            for piece in image_pieces:
                if provider == "anthropic":
                    message_history.append({
                        "role": "user",
                        "content": [
                            {
                                "type": "image",
                                "source": {
                                    "type": "base64",
                                    "media_type": "image/png",
                                    "data": piece.split(",", 1)[1]
                                }
                            }
                        ]
                    })
                else:
                    message_history.append({
                        "role": "user",
                        "content": [
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": piece
                                }
                            }
                        ]
                    })
    
    # Add the text prompt last
    message_history.append({"role": "user", "content": prompt})

    # Prepare request data
    request_data = {
        "messages": message_history,
        "max_tokens": 1500,
        "temperature": 0.7,
        "provider": provider,
        "model": model
    }
    
    # Send request to server
    try:
        response = requests.post(
            f"{server_url}/generate",
            json=request_data,
            headers={"Content-Type": "application/json"}
        )
        
        # Handle response
        if response.status_code == 200:
            result = response.json()
            if result.get("success", False):
                return result.get("content", "")
            else:
                error_msg = result.get("error", "Unknown error")
                raise Exception(f"Server error: {error_msg}")
        else:
            raise Exception(f"HTTP error: {response.status_code} - {response.text}")
            
    except requests.exceptions.RequestException as e:
        raise Exception(f"Connection error: {str(e)}")

def guess_image_mime_type(encoded_image):
    """Guess the MIME type of the image from the data URL"""
    if encoded_image.startswith("data:image/jpeg"):
        return "image/jpeg"
    elif encoded_image.startswith("data:image/png"):
        return "image/png"
    elif encoded_image.startswith("data:image/gif"):
        return "image/gif"
    elif encoded_image.startswith("data:image/webp"):
        return "image/webp"
    else:
        return "application/octet-stream"  # Default to binary data if unknown
    
def main():
    """Main function to run the Reich client."""
    Path(DIALOGUE_DIR).mkdir(exist_ok=True)
    
    # Parse command line arguments
    parser = argparse.ArgumentParser(description="Reich client for AI text generation")
    parser.add_argument('-f', '--file', default='prompt', help='File path to read prompt from')
    parser.add_argument("-i", "--images", nargs='+', required=False, help="Image files to send along with the prompt")
    parser.add_argument("-u", "--urls", nargs='+', required=False, help="URLs to capture screenshots from")
    parser.add_argument("-s", "--server", default=SERVER_URL, help=f"Server URL (default: {SERVER_URL})")
    parser.add_argument("-p", "--provider", default="openrouter", choices=["auto", "openai", "openrouter", "anthropic"])
    parser.add_argument("-m", "--model", default="anthropic/claude-3.7-sonnet", help="Model to use")

    args = parser.parse_args()
    
    # Process user input
    if args.file:
        with open(os.path.expanduser(args.file), 'r') as file:
            user_prompt = file.read()
    else:
        user_prompt = input("\nEnter your prompt: ")
    
    # Capture screenshots if URLs are provided
    captured_images = []
    if args.urls:
        for url in args.urls:
            screenshot_path = capture_webpage(url)
            captured_images.append(screenshot_path)
    
    # Combine captured screenshots with provided images
    image_paths = (args.images or []) + captured_images
    # Load context
    preamble = load_preamble() if os.path.exists(PREAMBLE_FILE) else ""
    exclusions = load_exclusions()
    context = gather_context(exclusions)
    
    # Prepare final prompt with context
    final_prompt = f"{preamble}\n\n{user_prompt}\n\n{context}"
    epoch_time, prompt_file, context_file = save_prompt(user_prompt, final_context=final_prompt)

    try:
        # Send request to AI server
        response_text = send_request_to_server(
            prompt=final_prompt, 
            image_paths=image_paths,
            server_url=args.server,
            provider=args.provider,
            model=args.model
        )
        
        # Parse and save response components (JSON format if available)
        response_file, patch_file, commands_file = save_response_components(epoch_time, response_text)
        
        # Extract and save code blocks if present
        code_blocks = re.findall(r'```(.*?)```', response_text, re.DOTALL)
        if code_blocks:
            Path(GENERATED_DIR).mkdir(exist_ok=True)
            for i, code_block in enumerate(code_blocks):
                code_block = code_block.strip()
                if code_block.startswith('python'):
                    extension = '.py'
                    content = code_block.split('\n', 1)[1] if '\n' in code_block else code_block
                elif code_block.startswith('javascript'):
                    extension = '.js'
                    content = code_block.split('\n', 1)[1] if '\n' in code_block else code_block
                else:
                    extension = '.txt'
                    content = code_block
                    
                filename = os.path.join(GENERATED_DIR, f"{epoch_time}_{i}{extension}")
                with open(filename, 'w') as file:
                    file.write(content)
        
        # Print the response
        print("\n" + "="*50)
        print("RESPONSE:")
        print("="*50)
        print(response_text)
        
        # Print information about any patches or commands
        is_json, text, patch, commands = parse_json_response(response_text)
        if is_json:
            if patch:
                patch_file = os.path.join("patches", f"{epoch_time}-patch.txt")
                print(f"\nPatch file saved to: {patch_file}")
                print("To apply the patch, run:")
                print(f"  git apply {patch_file}")
            
            if commands:
                print("\nCommands generated:")
                for i, cmd in enumerate(commands):
                    cmd_file = os.path.join("commands", f"{epoch_time}-cmd{i+1}.sh")
                    print(f"  [{i+1}] {cmd} (saved to {cmd_file})")
                print("\nTo run a command, execute:")
                print(f"  bash commands/{epoch_time}-cmd#.sh")
        
        # Update conversation summary
        #jif 'diarize' in sys.modules:
        #j    diarize.summarize_conversation()
            
    except Exception as e:
        print(f"Error in processing: {e}")
        return 1
        
    return 0

if __name__ == "__main__":
    sys.exit(main())


# Content of prompt:
Let's design a search tool that builds on url_fetch.py it will take keyword or list of keywords, use the GOogle Search JSON API (assume I have keys) to retrieve 5 results. Then it will use the screencapture flow from url_fetch to take screenshots of the first 5 results. Finally, it will use the LLM logic from composer.py to send the image to an LLM for summarization. 


# Content of example.config.json:
{
  "openai_api_key": "",
  "anthropic_api_key": "",
  "openrouter_api_key": ""
}


# Content of search_utils.py:
#!/usr/bin/env python3

import os
import sys
import json
import tempfile
import requests
from urllib.parse import quote


def process_keywords(keywords):
    """
    Process a list of keywords for search.
    
    Args:
        keywords (list): List of keyword strings
        
    Returns:
        str: Processed keywords ready for search
    """
    # Remove any empty strings and join with spaces
    processed = " ".join([k.strip() for k in keywords if k.strip()])
    return processed


def construct_search_url(query):
    """
    Construct a Google search URL from a query string.
    
    Args:
        query (str): Search query string
        
    Returns:
        str: Formatted Google search URL
    """
    encoded_query = quote(query)
    return f"https://www.google.com/search?q={encoded_query}"


def create_temp_directory():
    """
    Create a temporary directory to store screenshots.
    
    Returns:
        str: Path to the temporary directory
    """
    temp_dir = tempfile.mkdtemp(prefix="search_tool_")
    print(f"Created temporary directory for screenshots: {temp_dir}", file=sys.stderr)
    return temp_dir


def load_config(config_path="config.json"):
    """
    Load configuration from a JSON file.
    
    Args:
        config_path (str): Path to the config file
        
    Returns:
        dict: Configuration dictionary
    """
    if not os.path.exists(config_path):
        # Check if example config exists and copy it
        example_config = "example.config.json"
        if os.path.exists(example_config):
            print(f"Config file {config_path} not found. Please copy and modify {example_config}", file=sys.stderr)
        else:
            print(f"Config file {config_path} not found.", file=sys.stderr)
        return {}
        
    try:
        with open(config_path, 'r') as f:
            return json.load(f)
    except json.JSONDecodeError:
        print(f"Error parsing config file {config_path}", file=sys.stderr)
        return {}
    except Exception as e:
        print(f"Error loading config file: {e}", file=sys.stderr)
        return {}


def search_google_api(query, api_key, search_engine_id, num_results=5):
    """
    Search Google using the Custom Search JSON API.
    
    Args:
        query (str): Search query string
        api_key (str): Google API key
        search_engine_id (str): Google Custom Search Engine ID
        num_results (int): Number of results to return
        
    Returns:
        list: List of dictionaries containing search results
    """
    base_url = "https://www.googleapis.com/customsearch/v1"
    params = {
        'q': query,
        'key': api_key,
        'cx': search_engine_id,
        'num': min(num_results, 10)  # API allows max 10 results per request
    }
    
    try:
        response = requests.get(base_url, params=params)
        response.raise_for_status()  # Raise exception for HTTP errors
        
        search_results = response.json()
        
        if 'items' not in search_results:
            print("No search results found.", file=sys.stderr)
            return []
        
        results = []
        for item in search_results['items']:
            result = {
                'title': item.get('title', 'No title'),
                'link': item.get('link', ''),
                'snippet': item.get('snippet', 'No snippet available')
            }
            results.append(result)
            
        return results
        
    except requests.exceptions.RequestException as e:
        print(f"Error making API request: {e}", file=sys.stderr)
        return []
    except json.JSONDecodeError:
        print(f"Error parsing API response", file=sys.stderr)
        return []
    except Exception as e:
        print(f"Unexpected error during search: {e}", file=sys.stderr)
        return []
