

continue the generation of hte search_util.py file


Directory Structure:
.
├── composer.py
├── conductor.py
├── pyvenv.cfg
├── search_tool.py
└── url_fetch.py

1 directory, 5 files


# Content of search_tool.py:
#! python3.12

import os
import sys
import argparse
import json
import base64
import requests
from pathlib import Path
import time

# Import from existing modules
from url_fetch import capture_webpage
from search_utils import (
    process_keywords,
    search_google_api,
    load_config,
    create_temp_directory
)

# Constants
SERVER_URL = "http://localhost:5555/api"  # Composer.py server URL
RESULTS_DIR = "search_results"  # Directory to store search results

def parse_arguments():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="Search tool with screenshot capture and LLM summarization")
    parser.add_argument("keywords", nargs="+", help="Keywords to search for")
    parser.add_argument("-n", "--num-results", type=int, default=5, 
                        help="Number of search results to process (default: 5)")
    parser.add_argument("-m", "--model", default="x-ai/grok-2-vision-1212", 
                        help="LLM model to use for summarization")
    parser.add_argument("-p", "--provider", default="openrouter", 
                        choices=["openai", "anthropic", "openrouter"],
                        help="AI provider to use")
    parser.add_argument("-s", "--save", action="store_true", 
                        help="Save search results and summaries")
    parser.add_argument("-o", "--output-dir", 
                        help="Directory to save results (default: search_results)")
    return parser.parse_args()

def encode_image(image_path):
    """Encode image to base64 for sending to LLM."""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")

def prepare_prompt_for_screenshot(url, title, snippet):
    """Prepare a prompt for the LLM to analyze a screenshot."""
    return f"""Please analyze this screenshot of search result: {title}

URL: {url}

Context from search snippet: {snippet}

Provide a concise summary of what you see in the screenshot. Focus on the main content, key information, and how it relates to the search query. Ignore ads, navigation elements, and other UI components unless they're relevant to understanding the content."""

def prepare_summary_prompt(search_query, individual_summaries):
    """Prepare a prompt for the LLM to create a final summary of all results."""
    summaries_text = "\n\n".join([f"Result {i+1}: {summary}" for i, summary in enumerate(individual_summaries)])
    
    return f"""You searched for: {search_query}

Here are summaries of the top search results:

{summaries_text}

Please provide a comprehensive yet concise summary of these search results. Identify common themes, contradictions, and unique insights. Focus on answering the original search query based on the information available in these results."""

def send_to_llm(prompt, image_path=None, server_url=SERVER_URL, provider="openai", model="gpt-4o"):
    """Send a prompt and optional image to the LLM via composer.py server."""
    messages = []
    
    # Add image if provided
    if image_path:
        image_base64 = encode_image(image_path)
        
        if provider == "anthropic":
            messages.append({
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": "image/png",
                            "data": image_base64
                        }
                    }
                ]
            })
        else:  # OpenAI or OpenRouter format
            messages.append({
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{image_base64}"
                        }
                    }
                ]
            })
    
    # Add text prompt
    messages.append({"role": "user", "content": prompt})
    
    # Prepare request data
    request_data = {
        "messages": messages,
        "max_tokens": 1000,
        "temperature": 0.7,
        "provider": provider,
        "model": model
    }
    
    # Send request to composer.py server
    try:
        response = requests.post(
            f"{server_url}/generate",
            json=request_data,
            headers={"Content-Type": "application/json"}
        )
        
        # Handle response
        if response.status_code == 200:
            result = response.json()
            if result.get("success", False):
                return result.get("content", "")
            else:
                error_msg = result.get("error", "Unknown error")
                raise Exception(f"Server error: {error_msg}")
        else:
            raise Exception(f"HTTP error: {response.status_code} - {response.text}")
            
    except requests.exceptions.RequestException as e:
        raise Exception(f"Connection error: {str(e)}")

def save_results(query, search_results, screenshots, summaries, final_summary, output_dir):
    """Save search results, screenshots, and summaries to files."""
    # Create output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)
    
    # Generate timestamp for filenames
    timestamp = int(time.time())
    
    # Save search results as JSON
    search_results_file = os.path.join(output_dir, f"search_results_{timestamp}.json")
    with open(search_results_file, "w") as f:
        json.dump(search_results, f, indent=2)
    
    # Save individual summaries
    summaries_file = os.path.join(output_dir, f"summaries_{timestamp}.txt")
    with open(summaries_file, "w") as f:
        for i, summary in enumerate(summaries):
            f.write(f"Result {i+1}: {search_results[i]['title']}\n")
            f.write(f"URL: {search_results[i]['link']}\n")
            f.write(f"{summary}\n\n")
    
    # Save final summary
    final_summary_file = os.path.join(output_dir, f"final_summary_{timestamp}.txt")
    with open(final_summary_file, "w") as f:
        f.write(f"Search Query: {query}\n\n")
        f.write(final_summary)
    
    print(f"Results saved to {output_dir}/")
    return {
        "search_results": search_results_file,
        "summaries": summaries_file,
        "final_summary": final_summary_file,
        "screenshots": screenshots
    }

def main():
    """Main function to run the search tool."""
    # Parse arguments
    args = parse_arguments()
    
    # Process keywords into a search query
    search_query = " ".join(args.keywords)
    print(f"Searching for: {search_query}")
    
    # Set output directory
    output_dir = args.output_dir if args.output_dir else RESULTS_DIR
    
    # Create temp directory for screenshots
    temp_dir = create_temp_directory()
    
    try:
        # Search Google API
        search_results = search_google_api(search_query, num_results=args.num_results)
        print(f"Found {len(search_results)} results")
        
        # Take screenshots of each result
        screenshots = []
        for i, result in enumerate(search_results):
            print(f"Capturing screenshot for result {i+1}: {result['title']}")
            try:
                # Generate filename based on search result
                filename = f"result_{i+1}_{int(time.time())}.png"
                output_path = os.path.join(temp_dir, filename)
                
                # Capture screenshot
                screenshot_path = capture_webpage(result['link'], output_file=output_path)
                screenshots.append(screenshot_path)
                print(f"Screenshot saved: {screenshot_path}")
                
            except Exception as e:
                print(f"Error capturing screenshot for {result['link']}: {str(e)}")
                screenshots.append(None)
        
        # Analyze screenshots with LLM
        summaries = []
        for i, (result, screenshot) in enumerate(zip(search_results, screenshots)):
            if screenshot:
                print(f"Analyzing screenshot for result {i+1}")
                prompt = prepare_prompt_for_screenshot(
                    result['link'], 
                    result['title'], 
                    result.get('snippet', 'No snippet available')
                )
                
                # Send to LLM
                summary = send_to_llm(
                    prompt=prompt,
                    image_path=screenshot,
                    provider=args.provider,
                    model=args.model
                )
                
                summaries.append(summary)
                print(f"Analysis complete for result {i+1}")
            else:
                summaries.append("Screenshot capture failed for this result.")
        
        # Create final summary
        print("Creating final summary...")
        final_prompt = prepare_summary_prompt(search_query, summaries)
        final_summary = send_to_llm(
            prompt=final_prompt,
            provider=args.provider,
            model=args.model
        )
        
        print("\n" + "="*50)
        print("FINAL SUMMARY")
        print("="*50)
        print(final_summary)
        print("="*50)
        
        # Save results if requested
        if args.save:
            saved_files = save_results(
                search_query,
                search_results,
                screenshots,
                summaries,
                final_summary,
                output_dir
            )
            print(f"Results saved to {saved_files['final_summary']}")
        
    except Exception as e:
        print(f"Error: {str(e)}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())


# Content of composer.py:
import os
import json
import time
import base64
from typing import Dict, Any, Optional, List
from flask import Flask, request, jsonify
from openai import OpenAI
from anthropic import Anthropic

app = Flask(__name__)

# Load Configuration
def load_config():
    with open('config.json', 'r') as f:
        return json.load(f)

config = load_config()
openai_api_key = config.get("openai_api_key")
anthropic_api_key = config.get("anthropic_api_key")
openrouter_api_key = config.get("openrouter_api_key")

# Initialize Clients
openai_client = None
anthropic_client = None
openrouter_client = None

if openai_api_key:
    openai_client = OpenAI(api_key=openai_api_key)

if anthropic_api_key:
    anthropic_client = Anthropic(api_key=anthropic_api_key)

if openrouter_api_key:
    openrouter_client = OpenAI(base_url="https://openrouter.ai/api/v1",api_key=openrouter_api_key)

@app.route('/api/generate', methods=['POST'])
def generate():
    data = request.json
    model = data.get('model', 'gpt-4o')
    messages = data.get('messages', [])
    max_tokens = data.get('max_tokens', 4000)
    temperature = data.get('temperature', 0.7)
    provider = data.get('provider', 'openrouter')  # Default to OpenAI if not specified
    
    try:
        if provider == 'openai' and openai_client:
            response = openai_client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            return jsonify({
                'success': True,
                'content': response.choices[0].message.content.strip(),
                'model': model,
                'provider': 'openai'
            })
            
        elif provider == 'anthropic' and anthropic_client:
            # Convert OpenAI message format to Anthropic format
            anthropic_messages = []
            for msg in messages:
                anthropic_messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
            
            response = anthropic_client.messages.create(
                model="claude-3-7-sonnet-20250219" if model == "default" else model,
                max_tokens=max_tokens,
                messages=anthropic_messages
            )
            
            return jsonify({
                'success': True,
                'content': response.content[0].text.strip(),
                'model': model,
                'provider': 'anthropic'
            })
        elif provider == 'openrouter' and openrouter_client:
            response = openrouter_client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            return jsonify({
                'success': True,
                'content': response.choices[0].message.content.strip(),
                'model': model,
                'provider': 'openrouter'
            })
        else:
            return jsonify({
                'success': False,
                'error': f"Provider '{provider}' not available or no valid API keys found."
            }), 400
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    available_providers = []
    if openai_client:
        available_providers.append('openai')
    if anthropic_client:
        available_providers.append('anthropic')
    if anthropic_client:
        available_providers.append('openrouter')
        
    return jsonify({
        'status': 'ok',
        'available_providers': available_providers
    })

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5555))
    app.run(host='0.0.0.0', port=port, debug=True)


# Content of url_fetch.py:
import argparse
import time
import os
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from urllib.parse import urlparse

def capture_webpage(url, output_type='screenshot', output_file=None):
    # Set up headless Chrome
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--start-maximized")  # Ensures full-width capture
    driver = webdriver.Chrome(options=chrome_options)

    try:
        # Load the page
        driver.get(url)

        # Wait for page to load (adjust timeout and conditions as needed)
        wait = WebDriverWait(driver, 10)
        wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))

        # Additional wait to allow AJAX content to load
        time.sleep(5)

        # Create 'captures' directory if it doesn't exist
        os.makedirs('captures', exist_ok=True)

        # Generate filename from URL
        if output_file:
            filename = output_file
        else:
            parsed_url = urlparse(url)
            filename = parsed_url.netloc + parsed_url.path.replace('/', '_')
            if not filename.strip():
                filename = 'homepage'

        if output_type == 'screenshot':
            # Get the total height of the page
            total_height = driver.execute_script("return document.body.scrollHeight")
            
            # Set window size to capture full page
            driver.set_window_size(1920, total_height)
            
            # Take a full page screenshot
            screenshot_path = os.path.join('captures', f"{filename}.png")
            driver.save_screenshot(screenshot_path)
            print(f"Screenshot saved as {screenshot_path}")
            return screenshot_path
        elif output_type == 'content':
            # Get full page content
            page_content = driver.page_source
            content_path = os.path.join('captures', f"{filename}.html")
            with open(content_path, "w", encoding="utf-8") as f:
                f.write(page_content)
            print(f"Full page content saved as {content_path}")
            return content_path

    finally:
        driver.quit()

def main():
    parser = argparse.ArgumentParser(description="Capture webpage screenshot or content")
    parser.add_argument("url", help="URL to capture")
    parser.add_argument("--type", choices=['screenshot', 'content'], default='screenshot',
                        help="Type of capture: 'screenshot' or 'content' (default: screenshot)")
    parser.add_argument("-o", "--output", help="Output file name")
    
    args = parser.parse_args()
    
    capture_webpage(args.url, args.type, args.output)

if __name__ == "__main__":
    main()


# Content of pyvenv.cfg:
home = /opt/homebrew/opt/python@3.12/bin
include-system-site-packages = false
version = 3.12.9
executable = /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/bin/python3.12
command = /opt/homebrew/opt/python@3.12/bin/python3.12 -m venv /Users/steppe/reich


# Content of conductor.py:
import os
import time
import argparse
from PIL import Image
import io
import requests
import json
import sys
import base64
from pathlib import Path
from mimetypes import guess_type
import re
import glob
import subprocess

# Import the diarize module from the current project
import diarize
# import utility to 
from url_fetch import capture_webpage

# Constants
DIALOGUE_DIR = "dialogue/"
PREAMBLE_FILE = "preamble.txt"
EXCLUDE_FILE = "exclude.txt"
GENERATED_DIR = "generated/"
SERVER_URL = "http://localhost:5555/api"  # Default server URL

def get_epoch_time():
    return str(int(time.time()))

def encode_image(image_path):
    mime_type, _ = guess_type(image_path)
    if mime_type is None:
        mime_type = 'application/octet-stream'

    with open(image_path, "rb") as image_file:
        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')
    return f"data:{mime_type};base64,{base64_encoded_data}"

def process_image(image_path, max_height=7999):
    with Image.open(image_path) as img:
        width, height = img.size
        
        # Check if image needs to be split
        if height > width * 4/3 and height > max_height:
            pieces = []
            for i in range(0, height, max_height):
                box = (0, i, width, min(i+max_height, height))
                piece = img.crop(box)
                
                # Convert piece to base64
                buffer = io.BytesIO()
                piece.save(buffer, format="PNG")
                encoded_piece = base64.b64encode(buffer.getvalue()).decode('utf-8')
                pieces.append(f"data:image/png;base64,{encoded_piece}")
            
            return pieces
        else:
            # If image doesn't need splitting, return it as is
            return [encode_image(image_path)]

def save_prompt(prompt_text, final_context):
    epoch_time = get_epoch_time()
    prompt_file = os.path.join(DIALOGUE_DIR, f"{epoch_time}-prompt.txt")
    context_file = os.path.join(DIALOGUE_DIR, f"{epoch_time}-context.txt")
    
    try:
        with open(prompt_file, 'w') as f:
            f.write(prompt_text)

        with open(context_file, 'w') as f:
            f.write(final_context)

    except Exception as e:
        print(f"Error saving files: {e}")
    
    return epoch_time, prompt_file, context_file

def load_preamble():
    with open(PREAMBLE_FILE, 'r') as f:
        return f.read().strip()

def load_exclusions():
    if os.path.exists(EXCLUDE_FILE):
        with open(EXCLUDE_FILE, 'r') as f:
            return [line.strip() for line in f if line.strip()]
    return []

def generate_directory_structure(root_dir, exclude_file):
    exclude_list = []
    if os.path.exists(exclude_file):
        with open(exclude_file, 'r') as f:
            exclude_list = [line.strip() for line in f.readlines()]

    # Construct the tree command with excludes
    exclude_params = []
    for item in exclude_list:
        exclude_params.append(f"-I '{item}'")

    exclude_str = ' '.join(exclude_params)
    command = f"tree {root_dir} {exclude_str} --prune"
    
    # Execute the tree command
    result = subprocess.run(command, shell=True, capture_output=True, text=True)
    
    return result.stdout

def gather_context(exclusions):
    # Generate the directory structure
    dir_structure = generate_directory_structure('.', EXCLUDE_FILE)
    context = f"Directory Structure:\n{dir_structure}"
    
    all_files = [f for f in glob.glob("**/*", recursive=True) if os.path.isfile(f)]
    exclude_files = []
    exclude_dirs = []
    for pattern in exclusions:
        if '.' in pattern:
            exclude_files.append(pattern)
        else:
            exclude_dirs.append(pattern)

    # Append contents of files to the context, considering exclusions
    for file in all_files:
        if any(file.startswith(excluded_dir) for excluded_dir in exclude_dirs):
            continue
        if any(glob.fnmatch.fnmatch(file, pattern) for pattern in exclude_files):
            continue
        with open(file, 'r', errors="ignore") as f:
            context += f"\n\n# Content of {file}:\n"
            context += f.read()
    return context

def gather_message_history():
    files = sorted(glob.glob(os.path.join(DIALOGUE_DIR, "*.txt")), key=os.path.getmtime)
    summaries = [f for f in files if "summary" in f]
    prompts = [f for f in files if "prompt" in f]
    responses = [f for f in files if "response" in f]

    message_history = []

    if summaries:
        with open(summaries[-1], 'r') as f:
            message_history.append({"role": "assistant", "content": f.read().strip()})

    for p, r in zip(prompts, responses):
        with open(p, 'r') as f:
            message_history.append({"role": "user", "content": f.read().strip()})
        with open(r, 'r') as f:
            message_history.append({"role": "assistant", "content": f.read().strip()})

    return message_history

def send_request_to_server(prompt, image_paths=None, server_url=SERVER_URL, provider="openrouter", model="claude-3-7-sonnet-20250219"):
    message_history = gather_message_history()
    
    if image_paths:
        for image_path in image_paths:
            image_pieces = process_image(image_path)
            for piece in image_pieces:
                if provider == "anthropic":
                    message_history.append({
                        "role": "user",
                        "content": [
                            {
                                "type": "image",
                                "source": {
                                    "type": "base64",
                                    "media_type": "image/png",
                                    "data": piece.split(",", 1)[1]
                                }
                            }
                        ]
                    })
                else:
                    message_history.append({
                        "role": "user",
                        "content": [
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": piece
                                }
                            }
                        ]
                    })
    
    # Add the text prompt last
    message_history.append({"role": "user", "content": prompt})

    # Prepare request data
    request_data = {
        "messages": message_history,
        "max_tokens": 1500,
        "temperature": 0.7,
        "provider": provider,
        "model": model
    }
    
    # Send request to server
    try:
        response = requests.post(
            f"{server_url}/generate",
            json=request_data,
            headers={"Content-Type": "application/json"}
        )
        
        # Handle response
        if response.status_code == 200:
            result = response.json()
            if result.get("success", False):
                return result.get("content", "")
            else:
                error_msg = result.get("error", "Unknown error")
                raise Exception(f"Server error: {error_msg}")
        else:
            raise Exception(f"HTTP error: {response.status_code} - {response.text}")
            
    except requests.exceptions.RequestException as e:
        raise Exception(f"Connection error: {str(e)}")

def guess_image_mime_type(encoded_image):
    """Guess the MIME type of the image from the data URL"""
    if encoded_image.startswith("data:image/jpeg"):
        return "image/jpeg"
    elif encoded_image.startswith("data:image/png"):
        return "image/png"
    elif encoded_image.startswith("data:image/gif"):
        return "image/gif"
    elif encoded_image.startswith("data:image/webp"):
        return "image/webp"
    else:
        return "application/octet-stream"  # Default to binary data if unknown
    
def main():
    """Main function to run the Reich client."""
    Path(DIALOGUE_DIR).mkdir(exist_ok=True)
    
    # Parse command line arguments
    parser = argparse.ArgumentParser(description="Reich client for AI text generation")
    parser.add_argument('-f', '--file', default='prompt', help='File path to read prompt from')
    parser.add_argument("-i", "--images", nargs='+', required=False, help="Image files to send along with the prompt")
    parser.add_argument("-u", "--urls", nargs='+', required=False, help="URLs to capture screenshots from")
    parser.add_argument("-s", "--server", default=SERVER_URL, help=f"Server URL (default: {SERVER_URL})")
    parser.add_argument("-p", "--provider", default="openrouter", choices=["auto", "openai", "openrouter", "anthropic"])
    parser.add_argument("-m", "--model", default="anthropic/claude-3.7-sonnet", help="Model to use")

    args = parser.parse_args()
    
    # Process user input
    if args.file:
        with open(os.path.expanduser(args.file), 'r') as file:
            user_prompt = file.read()
    else:
        user_prompt = input("\nEnter your prompt: ")
    
    # Capture screenshots if URLs are provided
    captured_images = []
    if args.urls:
        for url in args.urls:
            screenshot_path = capture_webpage(url)
            captured_images.append(screenshot_path)
    
    # Combine captured screenshots with provided images
    image_paths = (args.images or []) + captured_images
    
    # Load context
    preamble = load_preamble() if os.path.exists(PREAMBLE_FILE) else ""
    exclusions = load_exclusions()
    context = gather_context(exclusions)
    
    # Prepare final prompt with context
    final_prompt = f"{preamble}\n\n{user_prompt}\n\n{context}"
    epoch_time, prompt_file, context_file = save_prompt(user_prompt, final_context=final_prompt)

    try:
        # Send request to AI server
        response_text = send_request_to_server(
            prompt=final_prompt, 
            image_paths=image_paths,
            server_url=args.server,
            provider=args.provider,
            model=args.model
        )
        
        # Save the response
        response_file = os.path.join(DIALOGUE_DIR, f"{epoch_time}-response.txt")
        with open(response_file, 'w') as f:
            f.write(response_text)
        
        # Extract and save code blocks if present
        code_blocks = re.findall(r'```(.*?)```', response_text, re.DOTALL)
        if code_blocks:
            Path(GENERATED_DIR).mkdir(exist_ok=True)
            for i, code_block in enumerate(code_blocks):
                code_block = code_block.strip()
                if code_block.startswith('python'):
                    extension = '.py'
                    content = code_block.split('\n', 1)[1] if '\n' in code_block else code_block
                elif code_block.startswith('javascript'):
                    extension = '.js'
                    content = code_block.split('\n', 1)[1] if '\n' in code_block else code_block
                else:
                    extension = '.txt'
                    content = code_block
                    
                filename = os.path.join(GENERATED_DIR, f"{epoch_time}_{i}{extension}")
                with open(filename, 'w') as file:
                    file.write(content)
        
        # Print the response
        print("\n" + "="*50)
        print("RESPONSE:")
        print("="*50)
        print(response_text)
        
        # Update conversation summary
        if 'diarize' in sys.modules:
            diarize.summarize_conversation()
            
    except Exception as e:
        print(f"Error in processing: {e}")
        return 1
        
    return 0

if __name__ == "__main__":
    sys.exit(main())
